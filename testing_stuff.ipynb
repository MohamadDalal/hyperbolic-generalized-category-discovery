{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from methods.clustering.faster_mix_k_means_pytorch import pairwise_distance\n",
    "from project_utils.lorentz import pairwise_dist as lorentz_pairwise_dist\n",
    "from project_utils.lorentz import pairwise_inner as lorentz_pairwise_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = torch.randn(10, 512)\n",
    "centers = torch.randn(5, 512)\n",
    "pair_dist = pairwise_distance(embeds, centers)\n",
    "dist2 = torch.matmul(embeds, centers.t())\n",
    "hyp_pair_dist = lorentz_pairwise_dist(embeds, centers, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n",
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "print(pair_dist.shape)\n",
    "print(dist2.shape)\n",
    "print(hyp_pair_dist.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1012.7142, 1023.2885,  989.1441, 1057.6973,  995.8853],\n",
      "        [1068.1846,  971.4751, 1031.1577, 1067.6117, 1085.8468],\n",
      "        [ 992.2310,  993.9666, 1010.7922,  958.0060,  971.3592],\n",
      "        [1059.5291,  995.1831,  894.7130, 1066.6942, 1057.3076],\n",
      "        [1044.4165,  980.5476,  969.7465, 1113.5642, 1017.2137],\n",
      "        [1189.9812,  985.1036, 1032.6238, 1051.2634, 1079.8756],\n",
      "        [1015.4780,  873.4585, 1013.3519, 1067.2152,  979.9601],\n",
      "        [1213.7441, 1045.0063, 1086.8579, 1049.1482, 1095.7402],\n",
      "        [1123.5165, 1035.3019, 1034.4357, 1037.2007, 1046.1222],\n",
      "        [1134.2799, 1051.1781, 1027.2856, 1138.2362, 1128.4786]])\n",
      "tensor([[ 29.3874, -25.6107, -14.6008, -13.9754,   8.1716],\n",
      "        [ 19.3349,  17.9787, -17.9249,  -1.2499, -19.1265],\n",
      "        [ 33.2585, -17.3201, -31.7953,  29.4998,  14.0641],\n",
      "        [  6.3797, -11.1581,  33.0146, -18.0740, -22.1398],\n",
      "        [ 11.1189,  -6.6574,  -7.3192, -44.3261,  -4.9099],\n",
      "        [-35.1894,  17.5385, -12.2839,  13.2982,  -9.7669],\n",
      "        [ 45.7036,  67.0024,  -9.0067,  -1.0364,  33.8321],\n",
      "        [-38.2889,  -3.6308, -30.6190,  23.1379,  -8.9172],\n",
      "        [-11.4593, -17.0628, -22.6921,  10.8274,  -2.3924],\n",
      "        [ -1.2923,  -9.4522,  -3.5683, -24.1417, -28.0219]])\n"
     ]
    }
   ],
   "source": [
    "print(pair_dist)\n",
    "print(dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9025, 0.7812, 0.5771, 0.0000, 0.5771, 0.7812, 0.9025],\n",
       "        [1.4796, 1.3583, 1.1542, 0.5771, 0.0000, 0.2041, 0.3254],\n",
       "        [1.6837, 1.5624, 1.3583, 0.7812, 0.2041, 0.0000, 0.1213],\n",
       "        [1.8050, 1.6837, 1.4796, 0.9025, 0.3254, 0.1213, 0.0000],\n",
       "        [1.8914, 1.7701, 1.5660, 0.9889, 0.4118, 0.2077, 0.0864],\n",
       "        [1.9585, 1.8372, 1.6331, 1.0560, 0.4789, 0.2748, 0.1535],\n",
       "        [2.0134, 1.8921, 1.6880, 1.1109, 0.5338, 0.3297, 0.2084]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = torch.arange(0, 7).float().view(-1, 1)\n",
    "center = torch.arange(-3, 4).float().view(-1, 1)\n",
    "torch.sqrt(pairwise_distance(embed, center))\n",
    "lorentz_pairwise_dist(embed, center, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4612])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.arange(0, 1, 0.1)\n",
    "logits = torch.zeros(10)\n",
    "logits[9] = 1\n",
    "target = torch.tensor([9])\n",
    "torch.nn.functional.cross_entropy(logits.view(1, -1), torch.tensor([target]).view(1), reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1244])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logits = -torch.arange(0, 1, 0.1)\n",
    "logits = torch.zeros(10)\n",
    "logits[9] = -1\n",
    "target = torch.tensor([9])\n",
    "torch.nn.functional.cross_entropy(logits.view(1, -1), torch.tensor([target]).view(1), reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing mappings between Euclidean, Lorentz and Klein models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.6450, 13.6450, 13.6450, 13.6450])\n",
      "tensor([27.3082, 13.6450, 13.6450, 13.6450, 13.6450])\n",
      "tensor([0.4997, 0.4997, 0.4997, 0.4997])\n",
      "tensor([0.4820, 0.4820, 0.4820, 0.4820])\n",
      "tensor([27.3079])\n",
      "tensor([0.9987])\n",
      "tensor([0.9293])\n"
     ]
    }
   ],
   "source": [
    "import project_utils.lorentz as L\n",
    "\n",
    "curv = 1.0\n",
    "\n",
    "a = 2*torch.tensor([1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "get_time = lambda x: torch.sqrt(1 / curv + torch.sum(x**2, dim=-1, keepdim=True))\n",
    "\n",
    "x_space = L.exp_map0(a, curv)\n",
    "x_time = get_time(x_space)\n",
    "\n",
    "x_K = x_space / x_time\n",
    "K_to_B = lambda x: (1/(1+torch.sqrt(1-torch.sum(x**2, dim=-1)))) * x\n",
    "x_B = K_to_B(x_K)\n",
    "x_BL = x_space / (1+x_time)\n",
    "\n",
    "#time_from_K = torch.sqrt(1 / (curv*(1 + torch.sum(x_K**2, dim=-1, keepdim=True))))\n",
    "time_from_K = torch.sqrt(1 / (curv*(1 - torch.sum(x_K**2, dim=-1, keepdim=True))))\n",
    "\n",
    "print(x_space)\n",
    "print(torch.cat([x_time, x_space], dim=-1))\n",
    "print(x_K)\n",
    "print(x_B)\n",
    "#print(x_BL)\n",
    "print(time_from_K)\n",
    "print(torch.sum(x_K**2, dim=-1, keepdim=True))\n",
    "print(torch.sum(x_B**2, dim=-1, keepdim=True))\n",
    "#print(torch.sum(x_BL**2, dim=-1, keepdim=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Mapped values can easily reach the edges of the circle in the Klein model. Euclidean vectors with length 3 are already reaching the edge. Embedding vectors need to be really clamped to be able to work with Einstein midpoint.\n",
    "\n",
    "I should consider just mapping to Euclidean to find the mean and then map the center. Maybe this will be an interesting ablation, but I will need severe normalization if I am to use Einstein midpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poincare to Klein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4038, 0.0000, 0.4038, 0.4038])\n",
      "tensor([0.5423, 0.0000, 0.5423, 0.5423])\n",
      "tensor([0.4038, 0.0000, 0.4038, 0.4038])\n",
      "tensor([0.8823])\n",
      "tensor([0.4891])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def poincare_exp_map0(x, curv: float = 1.0, eps: float = 1e-8):\n",
    "    \"\"\"\n",
    "    Map points from the tangent space at the vertex of hyperboloid, on to the\n",
    "    hyperboloid. This mapping is done using the exponential map of Poincare model.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape `(B, D)` giving batch of Euclidean vectors to project\n",
    "            onto the hyperboloid. These vectors are interpreted as velocity\n",
    "            vectors in the tangent space at the hyperboloid vertex.\n",
    "        curv: Positive scalar denoting negative hyperboloid curvature.\n",
    "        eps: Small float number to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of same shape as `x`, giving space components of the mapped\n",
    "        vectors on the hyperboloid.\n",
    "    \"\"\"\n",
    "\n",
    "    xnorm = torch.linalg.vector_norm(x, dim=-1, keepdim=True)\n",
    "    rc_xnorm = curv**0.5 * xnorm\n",
    "\n",
    "    # Ensure numerical stability in sinh by clamping input.\n",
    "    h_input = torch.clamp(rc_xnorm, min=eps, max=math.asinh(2**15))\n",
    "    _output = (torch.sinh(h_input)/(torch.cosh(h_input)+1)) * (x / torch.clamp(xnorm, min=eps))\n",
    "    return _output\n",
    "\n",
    "x_B = poincare_exp_map0(a, curv)\n",
    "B_to_K = lambda x: (2/(1+torch.sum(x**2, dim=-1))) * x\n",
    "K_to_B = lambda x: (1/(1+torch.sqrt(1-torch.sum(x**2, dim=-1)))) * x\n",
    "x_K = B_to_K(x_B)\n",
    "print(x_B)\n",
    "print(x_K)\n",
    "print(K_to_B(x_K))\n",
    "print(torch.sum(x_K**2, dim=-1, keepdim=True))\n",
    "print(torch.sum(x_B**2, dim=-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: For some reason the vector I get going from Lorentz to Klein is the same one I get from the Poincare exponential map. **What gives?**\n",
    "\n",
    "**I FOUND OUT** Turns out this is actually the Klein exponential map for curvature of 1. The derivation can be found in my notes, and I changed it to the Klein map in the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5688, 0.0000, 0.5688, 0.5688])\n",
      "tensor([0.4856, 0.0000, 0.4856, 0.4856])\n",
      "tensor([0.5688, 0.0000, 0.5688, 0.5688])\n",
      "tensor([0.9706])\n",
      "tensor([0.7074])\n"
     ]
    }
   ],
   "source": [
    "def klein_exp_map0(x, curv: float = 1.0, eps: float = 1e-8):\n",
    "    \"\"\"\n",
    "    Map points from the tangent space at the vertex of hyperboloid, on to the\n",
    "    hyperboloid. This mapping is done using the exponential map of Poincare model.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape `(B, D)` giving batch of Euclidean vectors to project\n",
    "            onto the hyperboloid. These vectors are interpreted as velocity\n",
    "            vectors in the tangent space at the hyperboloid vertex.\n",
    "        curv: Positive scalar denoting negative hyperboloid curvature.\n",
    "        eps: Small float number to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of same shape as `x`, giving space components of the mapped\n",
    "        vectors on the hyperboloid.\n",
    "    \"\"\"\n",
    "\n",
    "    xnorm = torch.linalg.vector_norm(x, dim=-1, keepdim=True)\n",
    "    rc_xnorm = curv**0.5 * xnorm\n",
    "\n",
    "    # Ensure numerical stability in sinh by clamping input.\n",
    "    tanh_input = torch.clamp(rc_xnorm, min=eps, max=math.asinh(2**15))\n",
    "    _output = torch.tanh(tanh_input) * x / torch.clamp(xnorm, min=eps)\n",
    "    return _output\n",
    "\n",
    "x_K = klein_exp_map0(a, curv)\n",
    "# These conversions don't really work since they do not account for curvature\n",
    "# Nevermind they work even without having an explicit curvature term, but that does not mean they are correct\n",
    "B_to_K = lambda x: (2/(1+torch.sum(x**2, dim=-1))) * x\n",
    "K_to_B = lambda x: (1/(1+torch.sqrt(1-torch.sum(x**2, dim=-1)))) * x\n",
    "# These conversions are from the survey and have curvature in them\n",
    "# But these don't make sense, since going from Klein to Poincare\n",
    "# Requires Klein points to have a max dot product of 1/c\n",
    "#B_to_K = lambda x: (2/(1+curv*torch.sum(x**2, dim=-1))) * x\n",
    "#K_to_B = lambda x: (1/(1+torch.sqrt(1-curv*torch.sum(x**2, dim=-1)))) * x\n",
    "x_B = K_to_B(x_K)\n",
    "print(x_K)\n",
    "print(x_B)\n",
    "print(B_to_K(x_B))\n",
    "print(torch.sum(x_K**2, dim=-1, keepdim=True))\n",
    "print(torch.sum(x_B**2, dim=-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with functions from the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9804, 2.9804, 2.9804, 2.9804])\n",
      "tensor([6.0026, 2.9804, 2.9804, 2.9804, 2.9804])\n",
      "tensor([0.3535, 0.3535, 0.3535, 0.3535])\n",
      "tensor([0.1464, 0.1464, 0.1464, 0.1464])\n",
      "tensor([1.0000])\n",
      "tensor([0.5000])\n",
      "tensor([0.0858])\n"
     ]
    }
   ],
   "source": [
    "import project_utils.lorentz as L\n",
    "from math import sqrt\n",
    "\n",
    "curv = 2.0\n",
    "\n",
    "a = 1*torch.tensor([1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "get_time = lambda x: torch.sqrt(1 / curv + torch.sum(x**2, dim=-1, keepdim=True))\n",
    "\n",
    "x_space = L.exp_map0(a, curv)\n",
    "x_time = get_time(x_space)\n",
    "\n",
    "x_temp = x_space / (sqrt(curv)*x_time)\n",
    "x_K = 2/(1+curv*torch.sum(x_temp**2, dim=-1, keepdim=True)) * x_temp\n",
    "K_to_B = lambda x: (1/(1+curv*torch.sqrt(1-torch.sum(x**2, dim=-1)))) * x\n",
    "x_B = K_to_B(x_K)\n",
    "x_BL = x_space / (1+x_time)\n",
    "\n",
    "#time_from_K = torch.sqrt(1 / (curv*(1 + torch.sum(x_K**2, dim=-1, keepdim=True))))\n",
    "time_from_K = torch.sqrt(1 / (curv*(1 - torch.sum(x_K**2, dim=-1, keepdim=True))))\n",
    "\n",
    "print(x_space)\n",
    "print(torch.cat([x_time, x_space], dim=-1))\n",
    "print(x_K)\n",
    "print(x_B)\n",
    "#print(x_BL)\n",
    "print(time_from_K)\n",
    "print(torch.sum(x_K**2, dim=-1, keepdim=True))\n",
    "print(torch.sum(x_B**2, dim=-1, keepdim=True))\n",
    "#print(torch.sum(x_BL**2, dim=-1, keepdim=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4022, 0.0000, 0.4022, 0.4022])\n",
      "tensor([0.4082, 0.0000, 0.4082, 0.4082])\n",
      "tensor([0.4022, 0.0000, 0.4022, 0.4022])\n",
      "tensor([0.4999])\n",
      "tensor([0.4853])\n"
     ]
    }
   ],
   "source": [
    "def poincare_exp_map0_old(x, curv: float = 1.0, eps: float = 1e-8):\n",
    "    \"\"\"\n",
    "    Map points from the tangent space at the vertex of hyperboloid, on to the\n",
    "    hyperboloid. This mapping is done using the exponential map of Poincare model.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape `(B, D)` giving batch of Euclidean vectors to project\n",
    "            onto the hyperboloid. These vectors are interpreted as velocity\n",
    "            vectors in the tangent space at the hyperboloid vertex.\n",
    "        curv: Positive scalar denoting negative hyperboloid curvature.\n",
    "        eps: Small float number to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of same shape as `x`, giving space components of the mapped\n",
    "        vectors on the hyperboloid.\n",
    "    \"\"\"\n",
    "\n",
    "    xnorm = torch.linalg.vector_norm(x, dim=-1, keepdim=True)\n",
    "    rc_xnorm = curv**0.5 * xnorm\n",
    "\n",
    "    # Ensure numerical stability in sinh by clamping input.\n",
    "    tanh_input = torch.clamp(rc_xnorm, min=eps, max=math.asinh(2**15))\n",
    "    _output = torch.tanh(tanh_input) * x / torch.clamp(rc_xnorm, min=eps)\n",
    "    return _output\n",
    "\n",
    "x_B = poincare_exp_map0_old(a, curv)\n",
    "# These conversions don't really work since they do not account for curvature\n",
    "# Nevermind they work even without having an explicit curvature term\n",
    "B_to_K = lambda x: (2/(1+curv*torch.sum(x**2, dim=-1))) * x\n",
    "K_to_B = lambda x: (1/(1+torch.sqrt(1-curv*torch.sum(x**2, dim=-1)))) * x\n",
    "x_K = B_to_K(x_B)\n",
    "print(x_B)\n",
    "print(x_K)\n",
    "print(K_to_B(x_K))\n",
    "print(torch.sum(x_K**2, dim=-1, keepdim=True))\n",
    "print(torch.sum(x_B**2, dim=-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Centroid Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0750, -0.0724, -0.0049,  0.0612, -0.0479,  0.0207, -0.0229,  0.0406,\n",
      "         0.0103,  0.0100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import project_utils.lorentz as L\n",
    "X = 1*torch.randn(512, 10)\n",
    "print(X.mean(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10]) torch.Size([512, 1])\n",
      "tensor([-0.0233, -0.0225, -0.0015,  0.0190, -0.0149,  0.0064, -0.0071,  0.0126,\n",
      "         0.0032,  0.0031])\n",
      "tensor([-0.0233, -0.0225, -0.0015,  0.0190, -0.0149,  0.0064, -0.0071,  0.0126,\n",
      "         0.0032,  0.0031])\n",
      "tensor([-38.3865, -37.0484,  -2.5233,  31.3243, -24.5357,  10.5811, -11.7083,\n",
      "         20.7877,   5.2845,   5.1183])\n",
      "tensor(929.1268)\n",
      "tensor(929.1268)\n",
      "tensor(3082.0398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdalal/Documents/AVS10_Files/hyperbolic-generalized-category-discovery/project_utils/lorentz.py:49: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n",
      "  xyl = x @ y.T - x_time @ y_time.T\n"
     ]
    }
   ],
   "source": [
    "curv = 1.0\n",
    "EM = L.einstein_midpoint(X, curv)\n",
    "EM2 = L.einstein_midpoint2(X, curv)\n",
    "C = L.centroid(X, curv)\n",
    "print(EM)\n",
    "print(EM2)\n",
    "print(C)\n",
    "print(L.pairwise_dist(X, EM, curv).sum())\n",
    "print(L.pairwise_dist(X, EM2, curv).sum())\n",
    "print(L.pairwise_dist(X, C, curv).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Use the Einstein midpoint without transforming to Klein"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
